{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1axzWhtkT1ixR8TzeNq3VzcrO6v1PS0CD",
      "authorship_tag": "ABX9TyPpCMKvMoyPygZv/XU8dvM6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fathima86/Stacking-Ensemble-based-MLP-for-AKI-prediction/blob/main/stackingMLPnew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NI4x_u410pk"
      },
      "outputs": [],
      "source": [
        " # 1. Importing Libraries                                  #                                      \n",
        "###############################################################################\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "#from mlxtend.classifier import StackingCVClassifier #\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "#from imblearn.ensemble import BalanceCascade\n",
        "#import smote_variants as sv\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123)\n",
        "data_kidney= pd.read_csv('kid.csv')\n",
        "data_kidney['classification'].value_counts()\n",
        "data_kidney = data_kidney.iloc[:,1:-1] #remove the id and unnamed column\n",
        "label_encoder = LabelEncoder()\n",
        "data_kidney.iloc[:,0] = label_encoder.fit_transform(data_kidney.iloc[:,0]).astype('float64')\n",
        "data_kidney.isna().sum() \n",
        "X = data_kidney.iloc[:,:-1].values\n",
        "y = data_kidney.iloc[:,-1].values\n",
        "#X = data_kidney.iloc[:, [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]].values\n",
        "#y = data_kidney.iloc[:, 0].values\n"
      ],
      "metadata": {
        "id": "lPQHmq051_kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "#                        2. Scale Data                                         #                                      \n",
        "###############################################################################"
      ],
      "metadata": {
        "id": "FzRgEEYM2Edd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ],
      "metadata": {
        "id": "lVy-8jMl2FuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#                        3. Create train and test set                         #\n",
        "###############################################################################"
      ],
      "metadata": {
        "id": "yvdqUtJL2IeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)"
      ],
      "metadata": {
        "id": "Ou0VKlh02K9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainX = X_train\n",
        "trainy = y_train\n",
        "testX = X_test\n",
        "testy = y_test"
      ],
      "metadata": {
        "id": "GIpmsbF92kWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#                                  4. MLP_1                                    #\n",
        "###############################################################################\n"
      ],
      "metadata": {
        "id": "J-YK70Ow3MMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 50, kernel_initializer = 'uniform', \n",
        "                     activation = 'relu', input_dim = 22))\n",
        "\n",
        "model.add(Dense(units = 1, kernel_initializer = 'uniform', \n",
        "                     activation = 'sigmoid'))\n",
        "\n",
        "model.add(Dense(units = 1, kernel_initializer = 'uniform', \n",
        "                     activation = 'sigmoid'))\n",
        "\n",
        "#model.compile(optimizer = 'adam', loss = 'binary_crossentropy',  metrics = ['accuracy'])\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
        "                   metrics = ['accuracy'])\n",
        "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
        "#model.fit(trainX, trainy, epochs=50,verbose=0)\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n",
        "import os\n",
        "folder = 'models'\n",
        "path1 = os.getcwd()\n",
        "if folder not in os.listdir(path1):\n",
        "    os.makedirs(folder)\n",
        "    \n",
        "filename = 'models/model_' + str(0) + '.h5'\n",
        "model.save(filename)\n",
        "print('>Saved %s' % filename)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70M0oe1f3PtF",
        "outputId": "b41bd0e6-f933-4bfe-89f4-0da8a4aebb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.847, Test: 0.850\n",
            ">Saved models/model_0.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#                                  5. MLP_2                                    #\n",
        "###############################################################################\n"
      ],
      "metadata": {
        "id": "4-OJ7Iz63SiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Dense(units = 150, kernel_initializer = 'uniform', \n",
        "                     activation = 'relu', input_dim =22))\n",
        "\n",
        "model1.add(Dense(units = 1, kernel_initializer = 'uniform', \n",
        "                     activation = 'sigmoid'))\n",
        "\n",
        "model1.add(Dense(units = 1, kernel_initializer = 'uniform', \n",
        "                     activation = 'sigmoid'))\n",
        "\n",
        "model1.add(Dense(units = 1, kernel_initializer = 'uniform', \n",
        "                     activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
        "                   metrics = ['accuracy'])\n",
        "  \n",
        "history = model1.fit(trainX, trainy, validation_data=(testX, testy), epochs=500, verbose=0)\n",
        "_, train_acc = model1.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model1.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n",
        "filename = 'models/model_' + str(1) + '.h5'\n",
        "model1.save(filename)\n",
        "print('>Saved %s' % filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZg2KEZa3Uot",
        "outputId": "5b342c11-75d1-4eb9-bfc1-0446c3cb8a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.847, Test: 0.850\n",
            ">Saved models/model_1.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#                                  6. MLP_3                                    #\n",
        "###############################################################################\n"
      ],
      "metadata": {
        "id": "ghUJkI4Q3YmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(units = 200, kernel_initializer = 'uniform', \n",
        "                     activation = 'relu', input_dim = 22))\n",
        "\n",
        "model2.add(Dense(units = 1, kernel_initializer = 'uniform', \n",
        "                     activation = 'sigmoid'))\n",
        "\n",
        "model2.add(Dense(units = 1, kernel_initializer = 'uniform', \n",
        "                     activation = 'sigmoid'))\n",
        "\n",
        "model2.add(Dense(units = 1, kernel_initializer = 'uniform', \n",
        "                     activation = 'sigmoid'))\n",
        "model2.add(Dense(units = 1, kernel_initializer = 'uniform', \n",
        "                     activation = 'sigmoid'))\n",
        "\n",
        "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
        "                   metrics = ['accuracy'])\n",
        "model2.fit(trainX, trainy, epochs=500, verbose=0)\n",
        "\n",
        "history = model2.fit(trainX, trainy, validation_data=(testX, testy), epochs=500, verbose=0)\n",
        "_, train_acc = model2.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model2.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n",
        "filename = 'models/model_' + str(2) + '.h5'\n",
        "model2.save(filename)\n",
        "print('>Saved %s' % filename)\n",
        "\n",
        "n_model = 3\n",
        "from keras.models import load_model\n",
        "def load_all_models(n_models):\n",
        "\tall_models = list()\n",
        "\tfor i in range(n_models):\n",
        "\t\tfilename = 'models/model_' + str(i) + '.h5'\n",
        "\t\tclassifier = load_model(filename)\n",
        "\t\tall_models.append(classifier)\n",
        "\t\tprint('>loaded %s' % filename)\n",
        "\treturn all_models\n",
        "\n",
        "n_members = 3\n",
        "members = load_all_models(n_members)\n",
        "print('Loaded %d models' % len(members))\n",
        "\n",
        "for classif in members:\n",
        "\t_, acc = classif.evaluate(testX, testy, verbose=0)\n",
        "\tprint('Model Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "bEEMvquG3bgV",
        "outputId": "8a83fee1-8891-4736-faeb-6ac84f9afd73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.847, Test: 0.850\n",
            ">Saved models/model_2.h5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c765c68becac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mn_members\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_members\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded %d models'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-c765c68becac>\u001b[0m in \u001b[0;36mload_all_models\u001b[0;34m(n_models)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'models/model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mall_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>loaded %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at models/model_0.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#                              7. Stacking                                    #\n",
        "###############################################################################"
      ],
      "metadata": {
        "id": "k99ZzJHj3iUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dstack\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef, roc_auc_score\n",
        "import statistics\n",
        "\n",
        "def stacked_dataset(members, inputX):\n",
        "\tstackX = None\n",
        "\tfor classifier in members:\n",
        "\t\tyhat = classifier.predict(inputX, verbose=0)\n",
        "\t\tif stackX is None:\n",
        "\t\t\tstackX = yhat\n",
        "\t\telse:\n",
        "\t\t\tstackX = dstack((stackX, yhat))\n",
        "\tstackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
        "\treturn stackX\n",
        "\n",
        "def fit_stacked_model(members, inputX, inputy):\n",
        "\tstackedX = stacked_dataset(members, inputX)\n",
        "\tmodel = GradientBoostingClassifier()\n",
        "\tmodel.fit(stackedX, inputy)\n",
        "\treturn model\n",
        "# model = fit_stacked_model(members, trainX, trainy)\n",
        "\n",
        "def stacked_prediction(members, model, inputX):\n",
        "\tstackedX = stacked_dataset(members, inputX)\n",
        "\tyhat = model.predict(stackedX)\n",
        "\treturn yhat\n",
        "# yhat = stacked_prediction(members, model, testX)\n",
        "\n",
        "accuracy = []\n",
        "f1_scores = []\n",
        "mcc_score = []\n",
        "auc_score = []\n",
        "sensitivity_score = []\n",
        "specificity_score = []\n",
        "\n",
        "cv = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
        "for train_index, test_index in cv.split(X):\n",
        "    X_train1, X_test1, y_train1, y_test1 = X[train_index], X[test_index], y[train_index], y[test_index]\n",
        "\n",
        "    model = fit_stacked_model(members, X_train1, y_train1)\n",
        "    yhat = stacked_prediction(members, model, X_test1)\n",
        "\n",
        "    acc = accuracy_score(y_test1, yhat)\n",
        "    print(acc)\n",
        "    f1 = f1_score(y_test1, yhat)\n",
        "    mcc = matthews_corrcoef(y_test1, yhat)\n",
        "    auc = roc_auc_score(y_test1, yhat)\n",
        "    cm = confusion_matrix(y_test1, yhat)\n",
        "    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "    specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "    \n",
        "    accuracy.append(acc)\n",
        "    f1_scores.append(f1)\n",
        "    mcc_score.append(mcc)\n",
        "    auc_score.append(auc)\n",
        "    sensitivity_score.append(sensitivity)\n",
        "    specificity_score.append(specificity)\n",
        "    \n",
        "print(\"Accuracy: \" + statistics.mean(accuracy).__str__())\n",
        "print(\"AUC: \" + statistics.mean(f1_scores).__str__())\n",
        "print(\"f1: \" + statistics.mean(mcc_score).__str__())\n",
        "print(\"MCCC: \" + statistics.mean(auc_score).__str__())\n",
        "print(\"Sensitivity: \" + statistics.mean(sensitivity_score).__str__())\n",
        "print(\"Specficity: \" + statistics.mean(specificity_score).__str__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "3Xsq1hBP3kqF",
        "outputId": "8cc09095-2654-4763-913c-e21d1b9c7460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-d7196f572f75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_stacked_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'members' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Model Accuracy: 0.98\n",
        "#Model Accuracy: 0.982\n",
        "#Model Accuracy: 0.982\n",
        "#Accuracy: 0.9969230769230769\n",
        "#AUC: 0.9972173913043478\n",
        "#f1: 0.9938557068711207\n",
        "#MCCC: 0.9970713073005093\n",
        "#Sensitivity: 0.9967741935483871\n",
        "#Specficity: 0.9973684210526316"
      ],
      "metadata": {
        "id": "9ijXtPeC3ohd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}